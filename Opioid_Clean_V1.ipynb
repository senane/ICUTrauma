{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "import statsmodels.api as sm\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "pd.set_option('display.max_columns', 9999)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding all opioids and nsaids given to patients\n",
    "\n",
    "opioids = ['hydromorphone','hydrocodone','morphine','oxycodone','oxymorphone','codeine','fentanyl','meperidine',\n",
    "          'tramadol','carfentanil','percocet','norco']\n",
    "\n",
    "nsaids = ['acetaminophen','amitriptyline', 'doxepin', 'imipramine', 'desipramine', 'nortriptyline',\n",
    "         'ibuprofen', 'naproxen', 'diclofenac', 'piroxicam', 'sulindac', 'indomethacin', 'ketorolac', 'meloxicam', \n",
    "          'celecoxib', 'ketoprofen', 'oxaprozin', 'toradol', 'valdecoxib', 'bextra', 'rofecoxib', 'vioxx', 'gabapentin', \n",
    "          'neurontin', 'cyclobenzaprine', 'duloxetine', 'cymbalta', 'pregabalin', 'lyrica', 'venlafaxine', 'effexor', \n",
    "          'tylenol', 'voltaren', 'naprosyn', 'paracetamol', 'aspirin']\n",
    "\n",
    "\n",
    "def opioids_nsaids (x, li):\n",
    "\n",
    "    for i in li:\n",
    "        if i in str(x).lower():\n",
    "            return 1\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = pd.read_csv('eicu-collaborative-research-database-2.0/medication.csv.gz')\n",
    "pts = pd.read_csv('eicu-collaborative-research-database-2.0/patient.csv.gz')\n",
    "hos = pd.read_csv('eicu-collaborative-research-database-2.0/hospital.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = med[med.drugordercancelled == 'No']\n",
    "\n",
    "cols_drop = ['medicationid',\n",
    "             'drugorderoffset',\n",
    "             'drugivadmixture',\n",
    "             'drugordercancelled',\n",
    "             'drughiclseqno',\n",
    "             'routeadmin',\n",
    "             'loadingdose',\n",
    "             'prn',\n",
    "             'gtc'\n",
    "            ]\n",
    "\n",
    "med.drop(columns=cols_drop, inplace=True)\n",
    "\n",
    "med['opioid'] = med.drugname.apply(lambda x: opioids_nsaids(x, opioids))\n",
    "med['nsaid'] = med.drugname.apply(lambda x: opioids_nsaids(x, nsaids))\n",
    "\n",
    "med = med[(med.opioid == 1) | (med.nsaid == 1)]\n",
    "\n",
    "mg = med.groupby(['patientunitstayid']).agg({'opioid': lambda x:sum(x), 'nsaid': lambda x:sum(x)})\n",
    "mg[mg != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def op_find (x, arr):\n",
    "    try:\n",
    "        return arr['opioid'][x]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def nsaid_find (x, arr):\n",
    "    try:\n",
    "        return arr['nsaid'][x]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = pts[pts.gender != 'Unknown']\n",
    "pts = pts[pts.gender != 'Other']\n",
    "\n",
    "pts['opioid'] = pts['patientunitstayid'].apply(lambda x: op_find(x, mg))\n",
    "pts['nsaid'] = pts['patientunitstayid'].apply(lambda x: nsaid_find(x, mg))\n",
    "\n",
    "pts = pd.merge(pts, hos, on=['hospitalid'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "\n",
    "pts['apacheadmissiondx'].fillna(value = 'N/A', inplace = True)\n",
    "pts['hospitaladmitsource'].fillna(value = 'Unknown', inplace = True)\n",
    "\n",
    "def age (x):\n",
    "    if x == '> 89':\n",
    "        return 90\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "pts['age'].fillna(value = 0, inplace = True)\n",
    "pts['age'] = pts['age'].apply(lambda x: age(x))\n",
    "\n",
    "pts.opioid.fillna(0, inplace = True)\n",
    "pts.nsaid.fillna(0, inplace = True)\n",
    "\n",
    "pts.opioid.replace(1.0,True,inplace=True)\n",
    "pts.opioid.replace(0.0,False,inplace=True)\n",
    "\n",
    "pts.nsaid.replace(1.0,True,inplace=True)\n",
    "pts.nsaid.replace(0.0,False,inplace=True)\n",
    "\n",
    "pts['painmeds'] = pts.opioid|pts.nsaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.to_csv('final_patients.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "Ethnicity vs. Pain Medication Administration (Either, NSAID Only, Opioid Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='painmeds',data=pts, estimator=np.mean)\n",
    "plt.xlabel('Patient Ethnicity')\n",
    "plt.ylabel('Proportion Receiving Pain Medications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='nsaid',data=pts, estimator=np.mean)\n",
    "plt.xlabel('Patient Ethnicity')\n",
    "plt.ylabel('Proportion Receiving NSAIDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='opioid',data=pts, estimator=np.mean)\n",
    "plt.xlabel('Patient Ethnicity')\n",
    "plt.ylabel('Proportion Receiving Opioids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Significance\n",
    "Chi-squared testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1:\n",
    "H<sub>0</sub>: Pain medication administration is independent of patient ethnicity.  \n",
    "H<sub>1</sub>: Pain medication administration is not independent of patient ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_eth = pd.crosstab(pts.painmeds, pts.ethnicity)\n",
    "ct_eth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(ct_eth)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We conclude there is a relationship between pain meds and ethnicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "##### Checking between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_aa_ = ct_eth[['African American','Caucasian']]\n",
    "c_aa_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(c_aa_)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Test 2:\n",
    "H<sub>0</sub>: NSAID administration is independent of patient ethnicity.  \n",
    "H<sub>1</sub>: NSAID administration is not independent of patient ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_ns = pd.crosstab(pts.nsaid, pts.ethnicity)\n",
    "ct_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(ct_ns)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_aa_ns = ct_ns[['African American','Caucasian']]\n",
    "c_aa_ns # do for all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(c_aa_ns)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We conclude there is a relationship between NSAIDs and ethnicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 3:\n",
    "H<sub>0</sub>: Opioid administration is independent of patient ethnicity.  \n",
    "H<sub>1</sub>: Opioid administration is not independent of patient ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_op = pd.crosstab(pts.opioid, pts.ethnicity)\n",
    "ct_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(ct_op)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_aa = ct_op[['African American','Caucasian']]\n",
    "c_aa # do for all groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(c_aa)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We conclude there is a relationship between Opioids and ethnicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Morphine Equivalence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi = pd.read_csv('opioids_final.csv')\n",
    "opi = pd.merge(opi, pts, on=['patientunitstayid'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi['mme_test'] = (opi.dos_mg.multiply(opi.doses_per_day)).multiply(opi.mme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi['mme_per_day']= np.multiply(opi['dos_mg'],opi['doses_per_day'])\n",
    "opi['mme_per_day']= np.multiply(opi['mme_per_day'],opi['mme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi_stat = opi[['patientunitstayid','mme_per_day']]\n",
    "#opi_stat.fillna(value='Other/Unknown', inplace=True)\n",
    "\n",
    "opi_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi[opi.mme_test < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(opi_stat, x='mme_per_day', aspect=5, height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='mme_per_day',data=opi_stat, estimator=np.mean)\n",
    "plt.xlabel('Ethnicity')\n",
    "plt.ylabel('MME per Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for Normal Distribution\n",
    "\n",
    "opi_stat_c = list(opi_stat[opi_stat.ethnicity == 'Caucasian'].mme_per_day)\n",
    "opi_stat_aa = list(opi_stat[opi_stat.ethnicity == 'African American'].mme_per_day)\n",
    "opi_stat_a = list(opi_stat[opi_stat.ethnicity == 'Asian'].mme_per_day)\n",
    "opi_stat_h = list(opi_stat[opi_stat.ethnicity == 'Hispanic'].mme_per_day)\n",
    "opi_stat_na = list(opi_stat[opi_stat.ethnicity == 'Native American'].mme_per_day)\n",
    "opi_stat_o = list(opi_stat[opi_stat.ethnicity == 'Other/Unknown'].mme_per_day)\n",
    "\n",
    "k_c, p_c = stat.kstest(opi_stat_c, 'norm')\n",
    "k_aa, p_aa = stat.kstest(opi_stat_aa, 'norm')\n",
    "k_a, p_a = stat.kstest(opi_stat_a, 'norm')\n",
    "k_h, p_h = stat.kstest(opi_stat_h, 'norm')\n",
    "k_na, p_na = stat.kstest(opi_stat_na, 'norm')\n",
    "k_o, p_o = stat.kstest(opi_stat_o, 'norm')\n",
    "\n",
    "print('Caucasian: k-value:', k_c, 'p-value:', p_c)\n",
    "print('African America: k-value:', k_aa, 'p-value:', p_aa)\n",
    "print('Asian: k-value:', k_a, 'p-value:', p_a)\n",
    "print('Hispanic: k-value:', k_h, 'p-value:', p_h)\n",
    "print('Native American: k-value:', k_na, 'p-value:', p_na)\n",
    "print('Other: k-value:', k_o, 'p-value:', p_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-normal distributions, using non-parametric Kruskal-Wallis H-test\n",
    "\n",
    "stat.kruskal(opi_stat_c,opi_stat_aa,opi_stat_a,opi_stat_h,opi_stat_na,opi_stat_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Multiple pairwise comparison (Tukey HSD) - whats the nonparametric equivalent?\n",
    "\n",
    "m_comp = pairwise_tukeyhsd(endog=opi_stat['mme_per_day'], groups=opi_stat['ethnicity'], alpha=0.05)\n",
    "m_comp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nemenyi = sp.posthoc_nemenyi(opi_stat, 'mme_per_day', 'ethnicity')\n",
    "nemenyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonferroni correction\n",
    "\n",
    "pvals = [] # grab pvals from nemenyi df above by columns\n",
    "\n",
    "for i in nemenyi.columns:\n",
    "    pvals = pvals + list(nemenyi[i])\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "p_adjusted = multipletests(pvals, alpha=0.05, method='bonferroni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Corrected alpha for Bonferroni method: ', p_adjusted[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = []\n",
    "group2 = []\n",
    "\n",
    "for col in nemenyi.columns:\n",
    "    for row in nemenyi.index:\n",
    "        group1.append(col)\n",
    "        group2.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'group1': group1, 'group2': group2, 'p_vals': p_adjusted[1], 'reject': p_adjusted[0]}\n",
    "\n",
    "nemenyi_comp = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nemenyi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still need to remove duplicates \n",
    "# (i.e., group1 = African American, group2 = Caucasian &  group1 = Caucasian, group2 = African American)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Square for Specific Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi_eth = pd.get_dummies(pts, columns=['ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opi_eth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_american = pd.crosstab(opi_eth.opioid, opi_eth['ethnicity_African American'])\n",
    "african_american"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(african_american)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asian = pd.crosstab(opi_eth.opioid, opi_eth['ethnicity_Asian'])\n",
    "asian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(asian)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caucasian = pd.crosstab(opi_eth.opioid, opi_eth['ethnicity_Caucasian'])\n",
    "caucasian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(caucasian)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hispanic = pd.crosstab(opi_eth.opioid, opi_eth['ethnicity_Hispanic'])\n",
    "hispanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(hispanic)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namerican = pd.crosstab(opi_eth.opioid, opi_eth['ethnicity_Native American'])\n",
    "namerican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(namerican)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = pd.crosstab(opi_eth.opioid, opi_eth['ethnicity_Other/Unknown'])\n",
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, p, dof, expected = stat.chi2_contingency(other)\n",
    "\n",
    "print('Pearson Chi-Square: ', c)\n",
    "print('p-value: ', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apache score\n",
    "\n",
    "apache = pd.read_csv('eicu-collaborative-research-database-2.0/apachePatientResult.csv.gz')\n",
    "\n",
    "apache = apache[apache['apacheversion']=='IV']\n",
    "apache_scores = apache[['patientunitstayid','apachescore','actualventdays']]\n",
    "pts = pd.merge(pts, apache_scores, on=['patientunitstayid'], how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.actualventdays.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcs score\n",
    "\n",
    "gcs = pd.read_csv('eicu-collaborative-research-database-2.0/apachePredVar.csv.gz')\n",
    "\n",
    "gcs = gcs[['patientunitstayid','verbal', 'motor', 'eyes']]\n",
    "gcs['gcs_score'] = gcs['verbal'] + gcs['motor'] + gcs['eyes']\n",
    "gcs = gcs[['patientunitstayid', 'gcs_score']]\n",
    "\n",
    "pts = pd.merge(pts, gcs, on=['patientunitstayid'], how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts['from_OR'] = pts['unitadmitsource'] == 'Operating Room'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admission HR\n",
    "\n",
    "systolic = pd.read_csv('eicu-collaborative-research-database-2.0/vitalPeriodic.csv.gz')\n",
    "systolic = systolic[['patientunitstayid', 'observationoffset', 'heartrate']]\n",
    "systolic.to_csv('heartrate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_systolic = systolic.groupby('patientunitstayid').apply(lambda x: x.sort_values('observationoffset'))\n",
    "\n",
    "first_values = grouped_systolic.drop_duplicates(subset='patientunitstayid', keep='first')\n",
    "first_values['hr_over100'] = first_values['heartrate'] >= 100\n",
    "first_values = first_values[['heartrate', 'hr_over100']]\n",
    "\n",
    "first_values.to_csv('heartrate2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_values = pd.read_csv('heartrate2.csv')\n",
    "pts = pd.merge(pts, first_values, on=['patientunitstayid'], how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts['ICU_duration'] = (pts['unitdischargeoffset'] - pts['hospitaladmitoffset'])/1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered protocols\n",
    "\n",
    "cpg = pd.read_csv('eicu-collaborative-research-database-2.0/carePlanGeneral.csv.gz')\n",
    "\n",
    "cpg = cpg[cpg.cplgroup == 'Ordered Protocols']\n",
    "cpg.drop(columns=['cplgeneralid', 'activeupondischarge', 'cplitemoffset', 'cplgroup'], inplace = True)\n",
    "cpg.drop_duplicates(inplace=True)\n",
    "\n",
    "cpg = cpg.groupby('patientunitstayid')['cplitemvalue'].apply(list).reset_index(name='orderedprotocols')\n",
    "cpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# one hot ecoding from list\n",
    "mlb = MultiLabelBinarizer()\n",
    "cpg = cpg.join(pd.DataFrame(mlb.fit_transform(cpg.pop('orderedprotocols')), columns=mlb.classes_, index=cpg.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = pts[(pts.admissionheight > 100)]\n",
    "pts = pts[(pts.admissionweight > 0) & (pts.admissionweight < 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pts.dropna(subset=['admissionheight','admissionweight'], inplace=True)\n",
    "pts.drop(columns=['Unnamed: 1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts['admissionheight'] = pts['admissionheight'].replace(0, pts['admissionheight'].median())\n",
    "pts['admissionweight'] = pts['admissionweight'].replace(0, pts['admissionweight'].median())\n",
    "pts['age'] = pts['age'].replace(0, pts['age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts['BMI'] = (pts.admissionweight/pts.admissionheight/pts.admissionheight)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pain scores\n",
    "pain = pd.read_csv('pain.csv')\n",
    "pts = pd.merge(pts, pain, on=['patientunitstayid'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final = pts[['patientunitstayid',\n",
    "                 'gender', \n",
    "                 'age', \n",
    "                 'ethnicity',\n",
    "                 'BMI', \n",
    "                 'actualventdays',\n",
    "                 'ICU_duration',\n",
    "                 'gcs_score', \n",
    "                 'apachescore', \n",
    "                 'from_OR',\n",
    "                 'heartrate',\n",
    "                 'teachingstatus',\n",
    "                 'numbedscategory',\n",
    "                 'opioid', \n",
    "                 'nsaid',\n",
    "                 'painmeds',\n",
    "                 'initialPain',\n",
    "                 'finalPain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.to_csv('final_patients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final = pd.merge(pts_final, opi_stat, on=['patientunitstayid'], how = 'left')\n",
    "pts_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.mme_per_day.fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final[\"painmeds\"] = pts_final[\"painmeds\"].astype(int)\n",
    "pts_final[\"opioid\"] = pts_final[\"opioid\"].astype(int)\n",
    "pts_final[\"nsaid\"] = pts_final[\"nsaid\"].astype(int)\n",
    "pts_final[\"from_OR\"] = pts_final[\"from_OR\"].astype(int)\n",
    "#pts_final[\"hr_over100\"] = pts_final[\"hr_over100\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.teachingstatus.replace('t', 1, inplace=True)\n",
    "pts_final.teachingstatus.replace('f', 0, inplace=True)\n",
    "\n",
    "pts_final.gender.replace('Male', 1, inplace=True)\n",
    "pts_final.gender.replace('Female', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.to_csv('pts_no_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final = pd.read_csv('pts_no_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final = pd.get_dummies(pts_final, columns = ['numbedscategory'], drop_first = False)\n",
    "pts_final = pd.get_dummies(pts_final, columns = ['ethnicity'], drop_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final = pd.merge(pts_final, cpg, on=['patientunitstayid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.to_csv('pts_dummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_drop = pts_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_drop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_drop.to_csv('pts_dummies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_df(df, norm_cols, drop_cols, y_col, drop=False, reg=0):\n",
    "    \"\"\"\n",
    "    df (string): CSV path.\n",
    "    cat_cols (list): categorical columns to one-hot-encode.\n",
    "    norm_cols (list): columns in df to normalize.\n",
    "    drop_cols (list): columns to drop.\n",
    "    y_col (string): variable of interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    #df = pd.read_csv('df')\n",
    "    #df = pd.get_dummies(df, columns = cat_cols, drop_first = drop)\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.datasets import load_iris\n",
    "    \n",
    "    df[norm_cols] = MinMaxScaler().fit_transform(df[norm_cols])\n",
    "    \n",
    "    if reg == 0:\n",
    "        X = df.drop(columns = drop_cols)\n",
    "        y = df[y_col]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "        \n",
    "        log = LogisticRegression(penalty='l1',solver='liblinear')\n",
    "        res = log.fit(X, y)\n",
    "        \n",
    "        #print(res)\n",
    "        #print(res.coef_, res.intercept_)\n",
    "        \n",
    "        logit_model = sm.Logit(y, X)\n",
    "        result = logit_model.fit(maxiter=1)\n",
    "\n",
    "        print(result.summary2())\n",
    "        \n",
    "        params = result.params\n",
    "        conf = result.conf_int()\n",
    "        conf['Odds Ratio'] = params\n",
    "        conf.columns = ['5%', '95%', 'Odds Ratio']\n",
    "        print(np.exp(conf))\n",
    "        print('==========================')\n",
    "        \n",
    "    elif reg == 1:\n",
    "        X = df.drop(columns = drop_cols)\n",
    "        y = df[y_col]\n",
    "        X = sm.add_constant(X)\n",
    "        \n",
    "        ols_model = sm.OLS(y,X)\n",
    "        result = ols_model.fit()\n",
    "        \n",
    "        print(result.summary())\n",
    "        \n",
    "        y_pred = result.predict(X)\n",
    "    \n",
    "    return result, y_pred, y, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Painmeds by Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth = ['ethnicity_Caucasian', 'ethnicity_African American', 'ethnicity_Asian',\n",
    "      'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown']\n",
    "\n",
    "for i in eth:\n",
    "    norm = ['actualventdays','age', 'gcs_score', 'apachescore']\n",
    "    dp = ['opioid', 'nsaid', 'patientunitstayid','painmeds','mme_per_day',i]\n",
    "    \n",
    "    print(\"Compared to \", i)\n",
    "    logreg_df(pts_final, norm, dp, 'painmeds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above Caucasian baseline, there was no significance with African Americans, so why is it not both ways?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically the above is saying compared to caucasians, hispanic and native american are signiciant \n",
    "# - both are more likely to receive pain meds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity vs. Receiving Opioids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth = ['ethnicity_Caucasian', 'ethnicity_African American', 'ethnicity_Asian',\n",
    "      'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown']\n",
    "\n",
    "for i in eth:\n",
    "    norm = ['actualventdays','age','gcs_score', 'apachescore']\n",
    "    dp = ['patientunitstayid','painmeds','opioid', i]\n",
    "    \n",
    "    print(\"Compared to \", i)\n",
    "    logreg_df(pts_final, norm, dp, 'opioid', reg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ethnicity vs. MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth = ['ethnicity_Caucasian', 'ethnicity_African American', 'ethnicity_Asian',\n",
    "      'ethnicity_Hispanic', 'ethnicity_Native American', 'ethnicity_Other/Unknown']\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in eth:\n",
    "    norm = ['actualventdays','age', 'gcs_score', 'apachescore']\n",
    "    dp = ['mme_per_day','patientunitstayid','painmeds','opioid', i]\n",
    "    \n",
    "    print(\"Compared to \", i)\n",
    "    ols, y_pred, y_true, X = logreg_df(pts_final, norm, dp, 'mme_per_day', reg=1)\n",
    "    models.append((y_pred, y_true, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "plt.plot(models[0][0], label=\"OLS\", alpha=0.5)\n",
    "plt.plot(models[0][1], label=\"True\", alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Patient Number')\n",
    "plt.ylabel('MME per Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_figs = pd.read_csv('pts_no_dummies.csv')\n",
    "pts_figs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='painmeds',data=pts_figs, estimator=np.mean)\n",
    "plt.xlabel('Patient Ethnicity')\n",
    "plt.ylabel('Proportion Receiving Pain Medications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='nsaid',data=pts_figs, estimator=np.mean)\n",
    "plt.xlabel('Patient Ethnicity')\n",
    "plt.ylabel('Proportion Receiving NSAIDs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='opioid',data=pts_figs, estimator=np.mean)\n",
    "plt.xlabel('Patient Ethnicity')\n",
    "plt.ylabel('Proportion Receiving Opioids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4.5))\n",
    "sns.barplot(x='ethnicity',y='mme_per_day',data=pts_figs, estimator=np.mean)\n",
    "plt.xlabel('Patient Ethnicity')\n",
    "plt.ylabel('MME per Day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "X = pts_final.drop(columns = ['mme_per_day','patientunitstayid','painmeds','opioid'])\n",
    "y = pts_final['mme_per_day']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake patient with figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/multiple-imputation-with-random-forests-in-python-dec83c0ac55b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
